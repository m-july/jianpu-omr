{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cf1d16-1855-4904-ae74-b97e02557f97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#import regex as re\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "import pickle\n",
    "#import json\n",
    "\n",
    "#import zhconv\n",
    "#import xpinyin\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 40)\n",
    "pd.set_option('display.min_rows', 40)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import openpyxl\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import sklearn\n",
    "\n",
    "import scipy\n",
    "\n",
    "import skimage\n",
    "import PIL\n",
    "\n",
    "#import sklearn\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import sklearn.preprocessing as preprocessing\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import wand\n",
    "#from wand.drawing import Drawing\n",
    "#from wand.image import Image\n",
    "\n",
    "import copy\n",
    "\n",
    "import threading\n",
    "\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4133747-ca33-4245-920b-bc489d9fcd82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 此部分要用到的常量\n",
    "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb17487-f91b-4cc6-a839-57e031784cf6",
   "metadata": {},
   "source": [
    "# [A] 图像读入与预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809bc3bb-b663-4212-b796-902cb1ab1903",
   "metadata": {},
   "source": [
    "### [A1] 获得 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7bdae4-4920-461f-86b5-cdc29c6b34b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def x_to_pq(x, W_b):\n",
    "    p = int(round(x // W_b))\n",
    "    q = x % W_b / (W_b / 2) - 1\n",
    "    return p, q\n",
    "\n",
    "def pq_to_x(p, q, W_b):\n",
    "    return p * W_b + (q + 1) / 2 * W_b\n",
    "\n",
    "def clamp_x(x, png_w):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    elif x >= png_w:\n",
    "        return png_w - 1\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d712afd4-9ab9-43af-a039-14f438c6af63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset_XN(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, ROOT, only_first_items=0, DESIRED_H=128, DESIRED_W=1280, only_first_x_csvs=0):\n",
    "        \n",
    "        self.ROOT = ROOT\n",
    "        self.DESIRED_H = DESIRED_H\n",
    "        self.DESIRED_W = DESIRED_W\n",
    "        \n",
    "        self.B = 80\n",
    "        self.F_main = 4\n",
    "        self.W_b = self.DESIRED_W / self.B\n",
    "        \n",
    "        # read self.DATA_DF\n",
    "        self.DATA_DF = pd.read_csv(os.path.join(ROOT, 'csv.csv'))\n",
    "        if only_first_x_csvs > 0:\n",
    "            self.DATA_DF = self.DATA_DF.iloc[:only_first_x_csvs+1]\n",
    "        \n",
    "        # group self.DATA_DF by png_file\n",
    "        self.DATA_GROUPED = self.DATA_DF.groupby('png_file')\n",
    "        self.DATA_KEYS = list(self.DATA_GROUPED.groups.keys())\n",
    "        \n",
    "        # pre-processing\n",
    "        self.preproc = {\n",
    "            'q_mu': 0,\n",
    "            'q_sigma': 1,\n",
    "            'l_mu': 0,\n",
    "            'l_sigma': 1,\n",
    "            'r_mu': 0,\n",
    "            'r_sigma': 1,\n",
    "        }\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        key = self.DATA_KEYS[index]\n",
    "        rows = self.DATA_GROUPED.get_group(key)\n",
    "        \n",
    "        # load image from disk\n",
    "        png_path = os.path.join(self.ROOT, 'png', key + '.png')\n",
    "        img = np.array(PIL.Image.open(png_path)).astype(np.float32) / 255\n",
    "        assert img.shape == (self.DESIRED_H, self.DESIRED_W)\n",
    "\n",
    "        # make tensor\n",
    "        x = torch.from_numpy(img)\n",
    "        \n",
    "        exception_num = 0\n",
    "        set_indicator = np.zeros(shape=(self.B,), dtype=bool)\n",
    "        to_y_main = np.zeros(shape=(self.B, self.F_main), dtype=np.float32)\n",
    "        to_y_type = np.zeros(shape=(self.B), dtype=np.int64)\n",
    "        to_y_dot_t = np.zeros(shape=(self.B), dtype=np.int64)\n",
    "        to_y_dot_b = np.zeros(shape=(self.B), dtype=np.int64)\n",
    "        to_y_dot_r = np.zeros(shape=(self.B), dtype=np.int64)\n",
    "        to_y_uline = np.zeros(shape=(self.B), dtype=np.int64)\n",
    "        for index, row in rows.iterrows():\n",
    "            x_c = clamp_x(row['x'], self.DESIRED_W)\n",
    "            x_min = clamp_x(row['x_min'], self.DESIRED_W)\n",
    "            x_max = clamp_x(row['x_max'], self.DESIRED_W)\n",
    "            p, q = x_to_pq(x_c, self.W_b)\n",
    "            if set_indicator[p]:\n",
    "                exception_num += 1\n",
    "            else:\n",
    "                set_indicator[p] = True\n",
    "                l = x_c - x_min\n",
    "                r = x_max - x_c\n",
    "                c = 1\n",
    "                to_y_main[p, 0] = (q - self.preproc['q_mu']) / self.preproc['q_sigma']\n",
    "                to_y_main[p, 1] = (l - self.preproc['l_mu']) / self.preproc['l_sigma']\n",
    "                to_y_main[p, 2] = (r - self.preproc['r_mu']) / self.preproc['r_sigma']\n",
    "                to_y_main[p, 3] = c\n",
    "                to_y_type[p] = row['type']\n",
    "                to_y_dot_t[p] = row['dot_t']\n",
    "                to_y_dot_b[p] = row['dot_b']\n",
    "                to_y_dot_r[p] = row['dot_r']\n",
    "                to_y_uline[p] = row['uline']\n",
    "\n",
    "        # to_y[~set_indicator, 3] = -self.preproc['c_mu']\n",
    "        y_main = torch.from_numpy(to_y_main)\n",
    "        y_type = torch.from_numpy(to_y_type)\n",
    "        y_dot_t = torch.from_numpy(to_y_dot_t)\n",
    "        y_dot_b = torch.from_numpy(to_y_dot_b)\n",
    "        y_dot_r = torch.from_numpy(to_y_dot_r)\n",
    "        y_uline = torch.from_numpy(to_y_uline)\n",
    "        return x, y_main, y_type, y_dot_t, y_dot_b, y_dot_r, y_uline, exception_num\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.DATA_KEYS)\n",
    "    \n",
    "    # def view_split_by_ratio(self, splits=[0.8,], seed=777):\n",
    "    #     main_view = np.arange(len(self.FILENAMES))\n",
    "    #     rng = np.random.default_rng(seed)\n",
    "    #     rng.shuffle(main_view)\n",
    "    #     assert len(splits) >= 1\n",
    "    #     split_begin = 0\n",
    "    #     result = []\n",
    "    #     for split in splits:\n",
    "    #         split_end = int(split * len(main_view))\n",
    "    #         result.append(main_view[split_begin:split_end])\n",
    "    #         split_begin = split_end\n",
    "    #     result.append(main_view[split_end:])\n",
    "    #     return [RowDatasetView(self, view) for view in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe3acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_y(y_main, y_type, y_dot_t, y_dot_b, y_dot_r, y_uline):\n",
    "    return {\n",
    "        'q': y_main[..., 0],\n",
    "        'l': y_main[..., 1],\n",
    "        'r': y_main[..., 2],\n",
    "        'c': y_main[..., 3],\n",
    "        'type': y_type,\n",
    "        'dot_t': y_dot_t,\n",
    "        'dot_b': y_dot_b,\n",
    "        'dot_r': y_dot_r,\n",
    "        'uline': y_uline,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b52d2-b879-4074-b540-f65e1c1e0a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inv_preproc(y, preproc):\n",
    "    yy = { key: y[key] for key in y if key not in ['q', 'l', 'r'] }\n",
    "    yy['q'] = y['q'] * preproc['q_sigma'] + preproc['q_mu']\n",
    "    yy['l'] = y['l'] * preproc['l_sigma'] + preproc['l_mu']\n",
    "    yy['r'] = y['r'] * preproc['r_sigma'] + preproc['r_mu']\n",
    "    return yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd10eeb-6dcd-4b41-8815-52b1a93d2ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class RowDatasetView(torch.utils.data.Dataset):\n",
    "    \n",
    "#     def __init__(self, database, view, type='theta_y'):\n",
    "#         self.database = database\n",
    "#         self.view = view\n",
    "#         self.type = type\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.view)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         return self.database.getitem(self.view[index], self.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db68f63-1f42-4a1b-b89b-169e54014e28",
   "metadata": {},
   "source": [
    "下面会显示 csv 的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353df80-270f-4943-860c-d1c18ac9d974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PNG_SMALL_FOLDER = \"..\\\\gen\\\\png_small\"\n",
    "# PNG_LARGE_FOLDER = \"..\\\\gen\\\\png_large\"\n",
    "# CSV_FOLDER = \"..\\\\gen\\\\csv\"\n",
    "# JSON_FOLDER = \"..\\\\gen\\\\json\"\n",
    "# len(os.listdir(CSV_FOLDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe778b6-938a-4363-85f5-8238878083a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "下面会显示图像的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb88e17-ec49-4565-8e00-a0c30a84be24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ACTIVE_NAME = '..\\\\gen_240824a\\\\div_240412_230605_585410'\n",
    "assert os.path.exists(ACTIVE_NAME)\n",
    "\n",
    "dataset_test = Dataset_XN(os.path.join(ACTIVE_NAME, 'xs_note_test'), only_first_x_csvs=0)\n",
    "dataset_train = Dataset_XN(os.path.join(ACTIVE_NAME, 'xs_note_train'), only_first_x_csvs=0)\n",
    "len(dataset_test)\n",
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c805246a-86c5-4336-b228-09817a4e9544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd8030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_TBRU_LABELS = ['0', '1', '2', '3+']\n",
    "Y_TYPE_LABELS = ['0', '1', '2', '3', '4', '5', '6', '7', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3b8385-828a-4c73-8b54-26716f207bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_info(dataset_train, dataset_test):\n",
    "    \n",
    "    lst_q = []\n",
    "    lst_l = []\n",
    "    lst_r = []\n",
    "    lst_c = []\n",
    "\n",
    "    lst_type = []\n",
    "    lst_dot_t = []\n",
    "    lst_dot_b = []\n",
    "    lst_dot_r = []\n",
    "    lst_uline = []\n",
    "    \n",
    "    e_num = 0\n",
    "    all_num = 0\n",
    "    for i in tqdm(list(range(len(dataset_train))), ascii=True):\n",
    "        x, y_main, y_type, y_t, y_b, y_r, y_u, e = dataset_train[i]\n",
    "        y = pack_y(y_main, y_type, y_t, y_b, y_r, y_u)\n",
    "        ct = (y['c'] >= 0.5)\n",
    "        all_num += torch.sum(ct).item()\n",
    "        e_num += e\n",
    "        lst_q.extend(y['q'][ct].tolist())\n",
    "        lst_l.extend(y['l'][ct].tolist())\n",
    "        lst_r.extend(y['r'][ct].tolist())\n",
    "        lst_c.extend(y['c'].tolist())\n",
    "        lst_type.extend(y['type'][ct].tolist())\n",
    "        lst_dot_t.extend(y['dot_t'][ct].tolist())\n",
    "        lst_dot_b.extend(y['dot_b'][ct].tolist())\n",
    "        lst_dot_r.extend(y['dot_r'][ct].tolist())\n",
    "        lst_uline.extend(y['uline'][ct].tolist())\n",
    "        \n",
    "    qs = np.array(lst_q)\n",
    "    ls = np.array(lst_l)\n",
    "    rs = np.array(lst_r)\n",
    "    cs = np.array(lst_c)\n",
    "    preproc = {\n",
    "            'q_mu': np.mean(qs) if len(lst_q) > 0 else 0,\n",
    "            'q_sigma': np.std(qs) if len(lst_q) > 0 else 1,\n",
    "            'l_mu': np.mean(ls) if len(lst_l) > 0 else 0,\n",
    "            'l_sigma': np.std(ls) if len(lst_l) > 0 else 1,\n",
    "            'r_mu': np.mean(rs) if len(lst_r) > 0 else 0,\n",
    "            'r_sigma': np.std(rs) if len(lst_r) > 0 else 1,\n",
    "    }\n",
    "        \n",
    "    for i in tqdm(list(range(len(dataset_test))), ascii=True):\n",
    "        x, y_main, y_type, y_t, y_b, y_r, y_u, e = dataset_test[i]\n",
    "        y = pack_y(y_main, y_type, y_t, y_b, y_r, y_u)\n",
    "        ct = (y['c'] >= 0.5)\n",
    "        all_num += torch.sum(ct).item()\n",
    "        e_num += e\n",
    "        lst_q.extend(y['q'][ct].tolist())\n",
    "        lst_l.extend(y['l'][ct].tolist())\n",
    "        lst_r.extend(y['r'][ct].tolist())\n",
    "        lst_c.extend(y['c'].tolist())\n",
    "        lst_type.extend(y['type'][ct].tolist())\n",
    "        lst_dot_t.extend(y['dot_t'][ct].tolist())\n",
    "        lst_dot_b.extend(y['dot_b'][ct].tolist())\n",
    "        lst_dot_r.extend(y['dot_r'][ct].tolist())\n",
    "        lst_uline.extend(y['uline'][ct].tolist())\n",
    "        \n",
    "    fig, (ax0, ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8) = plt.subplots(nrows=9, figsize=(6, 12))\n",
    "    ax0.hist(lst_q, bins=30)\n",
    "    ax0.set_title(\"Histogram of q\")\n",
    "    ax1.hist(lst_l, bins=30)\n",
    "    ax1.set_title(\"Histogram of l\")\n",
    "    ax2.hist(lst_r, bins=30)\n",
    "    ax2.set_title(\"Histogram of r\")\n",
    "    ax3.hist(lst_c, bins=30)\n",
    "    ax3.set_title(\"Histogram of c\")\n",
    "    fs_type = pd.Series(lst_type).value_counts().sort_index()\n",
    "    fs_type = pd.Series(fs_type.values, index=[Y_TYPE_LABELS[i] for i in fs_type.index])\n",
    "    fs_type.plot(kind='barh', ax=ax4)\n",
    "    ax4.set_title('Frequencies of y_type')\n",
    "    fs_dot_t = pd.Series(lst_dot_t).value_counts().sort_index()\n",
    "    fs_dot_t = pd.Series(fs_dot_t.values, index=[Y_TBRU_LABELS[i] for i in fs_dot_t.index])\n",
    "    fs_dot_t.plot(kind='barh', ax=ax5)\n",
    "    ax5.set_title('Frequencies of y_dot_t')\n",
    "    fs_dot_b = pd.Series(lst_dot_b).value_counts().sort_index()\n",
    "    fs_dot_b = pd.Series(fs_dot_b.values, index=[Y_TBRU_LABELS[i] for i in fs_dot_b.index])\n",
    "    fs_dot_b.plot(kind='barh', ax=ax6)\n",
    "    ax6.set_title('Frequencies of y_dot_b')\n",
    "    fs_dot_r = pd.Series(lst_dot_r).value_counts().sort_index()\n",
    "    fs_dot_r = pd.Series(fs_dot_r.values, index=[Y_TBRU_LABELS[i] for i in fs_dot_r.index])\n",
    "    fs_dot_r.plot(kind='barh', ax=ax7)\n",
    "    ax7.set_title('Frequencies of y_dot_r')\n",
    "    fs_uline = pd.Series(lst_uline).value_counts().sort_index()\n",
    "    fs_uline = pd.Series(fs_uline.values, index=[Y_TBRU_LABELS[i] for i in fs_uline.index])\n",
    "    fs_uline.plot(kind='barh', ax=ax8)\n",
    "    ax8.set_title('Frequencies of y_uline')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    \n",
    "    return all_num, e_num, preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae092f4e-1c21-4398-9765-606048685a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_num, e_num, preproc = get_info(dataset_train, dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a150336-3015-4b4a-83a6-cdf203f8d416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b39a8-a6d3-4a26-ac3c-eae06c6d8502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_test.preproc = preproc\n",
    "dataset_train.preproc = preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c585cb4-41ad-4bf7-86bc-694142d1f6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_num, e_num, preproc = get_info(dataset_train, dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073fbc0-71f2-427e-80b2-6f8cfadd6c1e",
   "metadata": {},
   "source": [
    "### [A2] 获得 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc6920e-2069-45af-85dc-ec966fe57184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=96, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=96, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4e856e-4677-4f5f-9d46-58ead1443cd9",
   "metadata": {},
   "source": [
    "有需要的话再执行下面这格，耗时比较大（10 batch/s）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03645a62-e4c7-4ad6-9113-8e3d4667aa02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #先设定fig和axes\n",
    "# #fig表示所有子图，axes表示一个个子图\n",
    "# fig, axes = plt.subplots(2, 1, figsize=(6, 6))\n",
    "\n",
    "# #因为没法直接可视化具体的dataloader，所以这里我们做一个循环用于分别收集theta_truth和y_truth的值\n",
    "# theta_values = []\n",
    "# y_values = []\n",
    "\n",
    "# for x, theta_truth, y_truth in tqdm(train_loader, ascii=True):\n",
    "#     theta_values.extend(theta_truth.tolist())\n",
    "#     y_values.extend(y_truth.tolist())\n",
    "    \n",
    "# for x, theta_truth, y_truth in tqdm(test_loader, ascii=True):\n",
    "#     theta_values.extend(theta_truth.tolist())\n",
    "#     y_values.extend(y_truth.tolist())\n",
    "\n",
    "# #用这些值画直方图\n",
    "# axes[0].hist(theta_values, bins=30)\n",
    "# axes[0].set_title(\"Histogram of theta_truth\")\n",
    "\n",
    "# axes[1].hist(y_values, bins=30)\n",
    "# axes[1].set_title(\"Histogram of y_truth\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01360431-dfdf-43c5-8276-bbadfe01ab68",
   "metadata": {},
   "source": [
    "# [B] 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f21a66-e783-44e7-8112-6d4b276b8767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WANDB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22828b97-4cca-425e-991e-9a372883dd29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#（可选）初始化 wandb\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"GP_240328_XsNotes\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"architecture\": \"CNN_BASELINE\",\n",
    "        \"dataset\": \"xsnotes\",\n",
    "        \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "WANDB = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0480f884-063e-4e45-a7cd-957e7ca79400",
   "metadata": {},
   "source": [
    "## [B1] 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b680728-81f6-42be-97d8-7baec8576b26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def sort_table_in_batch(tensor):\n",
    "#     first_col_data = tensor[:, :, 0]\n",
    "#     sorted_indices = torch.argsort(first_col_data, dim=1)\n",
    "#     result = torch.empty_like(tensor)\n",
    "#     for i, indices in enumerate(sorted_indices):\n",
    "#         result[i] = tensor[i][indices]\n",
    "#     return result\n",
    "# def sort_table_in_batch(tensor):\n",
    "#     argsort = torch.argsort(tensor[:, :, 0])\n",
    "#     result = tensor.gather(1, argsort.view(tensor.size(0), -1, 1).expand(-1, -1, tensor.size(2)))\n",
    "#     return result\n",
    "# while True:\n",
    "#     tensor = torch.rand(5, 5, 5)\n",
    "#     output1 = sort_table_in_batch_1(tensor)\n",
    "#     output2 = sort_table_in_batch_2(tensor)\n",
    "#     assert (output1 == output2).all()\n",
    "#     print('*', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc50b17-fd58-42e6-ac07-a31e372a046d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0, stride=1, bias=False, activation='tanh', dropout=0, bn=True, t=False):\n",
    "        super(Conv2D, self).__init__()\n",
    "        if t:\n",
    "            self.conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, padding=padding, stride=stride, bias=bias)\n",
    "        else:\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, stride=stride, bias=bias)\n",
    "        if bn:\n",
    "            self.bn = nn.BatchNorm2d(out_channels, eps=1e-5, momentum=0.1)\n",
    "        else:\n",
    "            self.bn = None\n",
    "        if activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation is None:\n",
    "            self.activation = None\n",
    "        else:\n",
    "            raise ValueError(\"Invalid param 'activation' provided: {}\".format(activation))\n",
    "        if dropout > 0:\n",
    "            self.dropout = nn.Dropout2d(dropout)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3edc3-421a-40a0-a676-1da4f312e921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True, activation='tanh', dropout=0, bn=True):\n",
    "        super(Linear, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, out_features, bias=bias)\n",
    "        if bn:\n",
    "            self.bn = nn.BatchNorm1d(out_features, eps=1e-5, momentum=0.1)\n",
    "        else:\n",
    "            self.bn = None\n",
    "        if activation == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation is None:\n",
    "            self.activation = None\n",
    "        else:\n",
    "            raise ValueError(\"Invalid param 'activation' provided: {}\".format(activation))\n",
    "        if dropout > 0:\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adea1e2-9200-4e92-8e72-c0c66508b12f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ablation exps should use other models defined in 'nns.py'\n",
    "\n",
    "class NoteRecog(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(NoteRecog, self).__init__() # in: (1x) 128 x 1280\n",
    "        \n",
    "        # p1280: 1 x 128 x 1280\n",
    "        self.p1280_convs = nn.Sequential(\n",
    "            Conv2D(1, 4, (7, 5), padding=(3, 2)), # 4 x 128 x 1280\n",
    "        )\n",
    "        self.p1280_step = nn.MaxPool2d((4, 2), stride=(4, 2)) # 4 x 32 x 640\n",
    "        self.p1280_skip = nn.Sequential(\n",
    "            Conv2D(4, 2, 1), # 2 x 32 x 640\n",
    "            nn.MaxPool2d((128, 16), stride=(128, 16)), # 2 x 1 x 80\n",
    "        )\n",
    "        \n",
    "        # p640: 4 x 32 x 640\n",
    "        self.p640_convs = nn.Sequential(\n",
    "            Conv2D(4, 8, 5, padding=2, dropout=0.005), # 8 x 32 x 640\n",
    "        )\n",
    "        self.p640_step = nn.MaxPool2d(2, stride=2) # 8 x 16 x 320\n",
    "        self.p640_skip = nn.Sequential(\n",
    "            Conv2D(8, 4, 1), # 4 x 16 x 320\n",
    "            nn.MaxPool2d((32, 8), stride=(32, 8)), # 4 x 1 x 80\n",
    "        )\n",
    "        \n",
    "        # p320: 8 x 12 x 320\n",
    "        self.p320_convs = nn.Sequential(\n",
    "            Conv2D(8, 14, 5, padding=2, dropout=0.01), # 14 x 16 x 320\n",
    "        )\n",
    "        self.p320_step = nn.MaxPool2d(2, stride=2) # 14 x 8 x 160\n",
    "        self.p320_skip = nn.Sequential(\n",
    "            Conv2D(14, 6, 1), # 3 x 8 x 160\n",
    "            nn.MaxPool2d((16, 4), stride=(16, 4)), # 4 x 1 x 80\n",
    "        )\n",
    "            \n",
    "        # p160: 12 x 8 x 160\n",
    "        self.p160_convs = nn.Sequential(\n",
    "            Conv2D(14, 24, 5, padding=2, dropout=0.015), # 18 x 8 x 160\n",
    "        )\n",
    "        self.p160_step = nn.MaxPool2d(2, stride=2) # 18 x 4 x 80\n",
    "        \n",
    "        # p80: 18 x 4 x 80\n",
    "        self.to_20 = nn.Sequential(\n",
    "            Conv2D(24, 64, (2, 4), stride=(1, 4), dropout=0.01), # 50 x 3 x 20\n",
    "        )\n",
    "        self.skip_20 = nn.Sequential(\n",
    "            Conv2D(64, 8, 1), # 50 x 3 x 20\n",
    "        )\n",
    "        self.to_5 = nn.Sequential(\n",
    "            Conv2D(64, 128, (2, 4), stride=(1, 4), dropout=0.01), # 128 x 2 x 5\n",
    "        )\n",
    "        self.skip_5 = nn.Sequential(\n",
    "            Conv2D(128, 24, 1), # 50 x 3 x 20\n",
    "        )\n",
    "        self.to_1 = nn.Sequential(\n",
    "            Conv2D(128, 400, (2, 5), stride=(1, 5), dropout=0.01), # 400 x 1 x 1\n",
    "        )\n",
    "        self.from_1 = nn.Sequential(\n",
    "            Conv2D(400, 64, (2, 5), stride=(1, 5), dropout=0.01, t=True), # 64 x 2 x 5\n",
    "        )\n",
    "        self.from_5 = nn.Sequential(\n",
    "            Conv2D(64+24, 16, (2, 4), stride=(1, 4), dropout=0.01, t=True), # 16 x 3 x 20\n",
    "        )\n",
    "        self.from_20 = nn.Sequential(\n",
    "            Conv2D(16+8, 6, (2, 4), stride=(1, 4), dropout=0.01, t=True), # 6 x 4 x 80\n",
    "        )\n",
    "        \n",
    "        # p80: (18+4) x 4 x 80\n",
    "        self.squeeze = nn.Sequential(\n",
    "            Conv2D(24+6, 68, (4, 1), stride=(4, 1)), # 24 x 1 x 80\n",
    "        )\n",
    "        \n",
    "        # p80: 50 x 1 x 80 (50 = 44 + 1 + 2 + 3)\n",
    "        self.fc_q = nn.Sequential( # 400 -> 1\n",
    "            Linear(80, 40, dropout=0.012, bn=False),\n",
    "            Linear(40, 20, dropout=0.006, bn=False),\n",
    "            Linear(20, 10, bn=False),\n",
    "            Linear(10, 5, bn=False),\n",
    "            Linear(5, 1, bn=False, activation=None),\n",
    "        )\n",
    "        self.fc_l = nn.Sequential( # 400 -> 1\n",
    "            Linear(80, 40, dropout=0.012, bn=False),\n",
    "            Linear(40, 20, dropout=0.006, bn=False),\n",
    "            Linear(20, 10, bn=False),\n",
    "            Linear(10, 5, bn=False),\n",
    "            Linear(5, 1, bn=False, activation=None),\n",
    "        )\n",
    "        self.fc_r = nn.Sequential( # 400 -> 1\n",
    "            Linear(80, 40, dropout=0.012, bn=False),\n",
    "            Linear(40, 20, dropout=0.006, bn=False),\n",
    "            Linear(20, 10, bn=False),\n",
    "            Linear(10, 5, bn=False),\n",
    "            Linear(5, 1, bn=False, activation=None),\n",
    "        )\n",
    "        self.fc_c = nn.Sequential( # 400 -> 1\n",
    "            Linear(80, 40, dropout=0.012, bn=False),\n",
    "            Linear(40, 20, dropout=0.006, bn=False),\n",
    "            Linear(20, 10, bn=False),\n",
    "            Linear(10, 5, bn=False),\n",
    "            Linear(5, 1, bn=False, activation='sigmoid'),\n",
    "        )\n",
    "        self.fc_type = nn.Sequential( # 400 -> 9\n",
    "            Linear(80, 55, dropout=0.012, bn=False),\n",
    "            Linear(55, 38, dropout=0.006, bn=False),\n",
    "            Linear(38, 24, bn=False),\n",
    "            Linear(24, 16, bn=False),\n",
    "            Linear(16, 9, bn=False),\n",
    "        )\n",
    "        self.fc_dot_t = nn.Sequential( # 400 -> 4\n",
    "            Linear(80, 50, dropout=0.012, bn=False),\n",
    "            Linear(50, 28, dropout=0.006, bn=False),\n",
    "            Linear(28, 16, bn=False),\n",
    "            Linear(16, 8, bn=False),\n",
    "            Linear(8, 4, bn=False),\n",
    "        )\n",
    "        self.fc_dot_b = nn.Sequential( # 400 -> 4\n",
    "            Linear(80, 50, dropout=0.012, bn=False),\n",
    "            Linear(50, 28, dropout=0.006, bn=False),\n",
    "            Linear(28, 16, bn=False),\n",
    "            Linear(16, 8, bn=False),\n",
    "            Linear(8, 4, bn=False),\n",
    "        )\n",
    "        self.fc_dot_r = nn.Sequential( # 400 -> 4\n",
    "            Linear(80, 50, dropout=0.012, bn=False),\n",
    "            Linear(50, 28, dropout=0.006, bn=False),\n",
    "            Linear(28, 16, bn=False),\n",
    "            Linear(16, 8, bn=False),\n",
    "            Linear(8, 4, bn=False),\n",
    "        )\n",
    "        self.fc_uline = nn.Sequential( # 400 -> 4\n",
    "            Linear(80, 50, dropout=0.012, bn=False),\n",
    "            Linear(50, 28, dropout=0.006, bn=False),\n",
    "            Linear(28, 16, bn=False),\n",
    "            Linear(16, 8, bn=False),\n",
    "            Linear(8, 4, bn=False),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1) # 320 x 1280 -> 1 x 320 x 1280, watch out for batch!\n",
    "        \n",
    "        x = self.p1280_convs(x)\n",
    "        p1280_skipped = self.p1280_skip(x)\n",
    "        x = self.p1280_step(x)\n",
    "        \n",
    "        x = self.p640_convs(x)\n",
    "        p640_skipped = self.p640_skip(x)\n",
    "        x = self.p640_step(x)\n",
    "        \n",
    "        x = self.p320_convs(x)\n",
    "        p320_skipped = self.p320_skip(x)\n",
    "        x = self.p320_step(x)\n",
    "        \n",
    "        x = self.p160_convs(x)\n",
    "        x = self.p160_step(x)\n",
    "        \n",
    "        xxx = self.to_20(x)\n",
    "        x20_skipped = self.skip_20(xxx)\n",
    "        xxx = self.to_5(xxx)\n",
    "        x5_skipped = self.skip_5(xxx)\n",
    "        xxx = self.to_1(xxx)\n",
    "        xxx = self.from_1(xxx)\n",
    "        xxx = self.from_5(torch.cat([xxx, x5_skipped], axis=1))\n",
    "        xxx = self.from_20(torch.cat([xxx, x20_skipped], axis=1))\n",
    "        x = self.squeeze(torch.cat([x, xxx], dim=1))\n",
    "        \n",
    "        x = torch.cat([x, p1280_skipped, p640_skipped, p320_skipped], axis=1).squeeze(-2).transpose(-1, -2)\n",
    "        return {\n",
    "            'q': self.fc_q(x).squeeze(-1),\n",
    "            'l': self.fc_l(x).squeeze(-1),\n",
    "            'r': self.fc_r(x).squeeze(-1),\n",
    "            'c': self.fc_c(x).squeeze(-1),\n",
    "            'type': self.fc_type(x),\n",
    "            'dot_t': self.fc_dot_t(x),\n",
    "            'dot_b': self.fc_dot_b(x),\n",
    "            'dot_r': self.fc_dot_r(x),\n",
    "            'uline': self.fc_uline(x),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959b309e-c63b-4ef8-a5bd-fb6b53fba17f",
   "metadata": {},
   "source": [
    "## [B2] 定义评估指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be3365-5db0-4031-8205-4459b46c0a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_eval(y, y_truth):\n",
    "    \n",
    "    c_dist = torch.sum(torch.abs(y['c'] - y_truth['c'])).item()\n",
    "    cc = (y['c'] >= 0.5)\n",
    "    ct = (y_truth['c'] >= 0.5)\n",
    "    c_tp = torch.sum(cc & ct).item()\n",
    "    c_fn = torch.sum(~cc & ct).item()\n",
    "    c_fp = torch.sum(cc & ~ct).item()\n",
    "    c_tn = torch.sum(~cc & ~ct).item()\n",
    "    \n",
    "    q_diff = torch.abs(y['q'][ct] - y_truth['q'][ct])\n",
    "    q_dist = torch.sum(q_diff).item()\n",
    "    q_0_3_acc = torch.sum(q_diff <= 0.3).item()\n",
    "    q_0_1_acc = torch.sum(q_diff <= 0.1).item()\n",
    "    \n",
    "    l_diff = torch.abs(y['l'][ct] - y_truth['l'][ct])\n",
    "    l_dist = torch.sum(l_diff).item()\n",
    "    l_6_acc = torch.sum(l_diff <= 6).item()\n",
    "    l_2_acc = torch.sum(l_diff <= 2).item()\n",
    "    \n",
    "    r_diff = torch.abs(y['r'][ct] - y_truth['r'][ct])\n",
    "    r_dist = torch.sum(r_diff).item()\n",
    "    r_6_acc = torch.sum(r_diff <= 6).item()\n",
    "    r_2_acc = torch.sum(r_diff <= 2).item()\n",
    "\n",
    "    type_acc = torch.sum(torch.argmax(y['type'], dim=-1)[ct] == y_truth['type'][ct])\n",
    "    dot_t_acc = torch.sum(torch.argmax(y['dot_t'], dim=-1)[ct] == y_truth['dot_t'][ct])\n",
    "    dot_b_acc = torch.sum(torch.argmax(y['dot_b'], dim=-1)[ct] == y_truth['dot_b'][ct])\n",
    "    dot_r_acc = torch.sum(torch.argmax(y['dot_r'], dim=-1)[ct] == y_truth['dot_r'][ct])\n",
    "    uline_acc = torch.sum(torch.argmax(y['uline'], dim=-1)[ct] == y_truth['uline'][ct])\n",
    "    \n",
    "    return {\n",
    "        'c_dist': c_dist,\n",
    "        'c_tp': c_tp,\n",
    "        'c_tn': c_tn,\n",
    "        'c_fn': c_fn,\n",
    "        'c_fp': c_fp,\n",
    "        \n",
    "        'ccc_q_dist': q_dist,\n",
    "        'ccc_q_0_3_acc': q_0_3_acc,\n",
    "        'ccc_q_0_1_acc': q_0_1_acc,\n",
    "        \n",
    "        'ccc_l_dist': l_dist,\n",
    "        'ccc_l_6_acc': l_6_acc,\n",
    "        'ccc_l_2_acc': l_2_acc,\n",
    "        \n",
    "        'ccc_r_dist': r_dist,\n",
    "        'ccc_r_6_acc': r_6_acc,\n",
    "        'ccc_r_2_acc': r_2_acc,\n",
    "\n",
    "        'ccc_type_acc': type_acc,\n",
    "        'ccc_dot_t_acc': dot_t_acc,\n",
    "        'ccc_dot_b_acc': dot_b_acc,\n",
    "        'ccc_dot_r_acc': dot_r_acc,\n",
    "        'ccc_uline_acc': uline_acc,\n",
    "        \n",
    "        'items': y['c'].size(0) * y['c'].size(1),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e197ca36-1b35-409e-a783-37314f77c249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def y_to_lbls(y_main, preproc, W_b, w, conf_threshold=None):\n",
    "    \n",
    "    yy = inv_preproc(y_main, preproc)\n",
    "\n",
    "    ccc = yy['c'].detach().cpu().numpy()\n",
    "    qqq = yy['q'].detach().cpu().numpy()\n",
    "    lll = yy['l'].detach().cpu().numpy()\n",
    "    rrr = yy['r'].detach().cpu().numpy()\n",
    "    \n",
    "    # print('yy:')\n",
    "    # print(yy)\n",
    "    \n",
    "    def clamp(v, low, high):\n",
    "        return low if v < low else (high if v > high else v)\n",
    "    \n",
    "    lbls = []\n",
    "    for m in range(ccc.shape[0]):\n",
    "        lbls_img = []\n",
    "        for p in range(ccc.shape[1]):\n",
    "            conf = ccc[m, p]\n",
    "            if (conf_threshold is None) or conf >= conf_threshold:\n",
    "                x0 = pq_to_x(p, qqq[m, p], W_b)\n",
    "                l = x0 - lll[m, p]\n",
    "                r = x0 + rrr[m, p]\n",
    "                lbls_box = [l, r, clamp(conf, 0, 1)]\n",
    "                lbls_img.append(lbls_box)\n",
    "        lbls.append(lbls_img)\n",
    "    \n",
    "    return lbls\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \n",
    "    l1, r1, _ = box1\n",
    "    l2, r2, _ = box2\n",
    "    \n",
    "    overlap = max(0, min(r1, r2) - max(l1, l2))\n",
    "    union = max(0, max(r1, r2) - min(l1, l2))\n",
    "    \n",
    "    iou = (overlap / union) if union > 0 else 0\n",
    "    return iou\n",
    "\n",
    "def compute_AP(P, G, iou_threshold=0.5):\n",
    "    \n",
    "    import warnings\n",
    "    \n",
    "    ious = np.zeros((len(P), len(G)))\n",
    "    for i in range(len(P)):\n",
    "        for j in range(len(G)):\n",
    "            ious[i,j] = compute_iou(P[i], G[j])\n",
    "    ious = (ious >= iou_threshold).astype(int)  # IoU threshold\n",
    "    \n",
    "    prediction_counts = np.sum(ious, axis=1)\n",
    "    prediction_correctness = (prediction_counts > 0).astype(int)\n",
    "    \n",
    "    prediction_confidence = [p[-1] for p in P]\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=UserWarning)\n",
    "        return average_precision_score(prediction_correctness, prediction_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74cae2-a60c-42ba-ac54-c2381d2a611f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def pr_curve(P, G, iou_threshold=0.5, output_name=None):\n",
    "    ious = np.zeros((len(P), len(G)))\n",
    "    for i in range(len(P)):\n",
    "        for j in range(len(G)):\n",
    "            ious[i,j] = compute_iou(P[i], G[j])\n",
    "    ious = (ious >= iou_threshold).astype(int)\n",
    "    prediction_counts = np.sum(ious, axis=1)\n",
    "\n",
    "    prediction_correctness = (prediction_counts > 0).astype(int)\n",
    "\n",
    "    prediction_confidence = [p[-1] for p in P]\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(prediction_correctness, prediction_confidence)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    ax.step(recall, precision, color='b', alpha=0.2,where='post')\n",
    "    ax.fill_between(recall, precision, step='post', alpha=0.2,color='b')\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_title('Precision-Recall Curve\\n(of one image)')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    if output_name is not None:\n",
    "        fig.savefig(output_name)\n",
    "        plt.close(fig=fig)\n",
    "\n",
    "# Call the function with your Predictions P, and GroundTruths G\n",
    "#pr_curve(P, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8f7bc4-e125-49be-a24b-e52393a5dc3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_epoch(model, test_loader, preproc, W_b, w, debug=False, use_large=False, pr_curve_output_path=None):\n",
    "    \n",
    "    AP30s = []\n",
    "    AP50s = []\n",
    "    AP70s = []\n",
    "    weights = []\n",
    "    \n",
    "    first_flag = 3\n",
    "    \n",
    "    item_count = 0\n",
    "    info_sum = None\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y_main, y_type, y_t, y_b, y_r, y_u, _ in tqdm(test_loader, ascii=True) if debug else test_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            y_main = y_main.to(DEVICE)\n",
    "            y_type = y_type.to(DEVICE)\n",
    "            y_t = y_t.to(DEVICE)\n",
    "            y_b = y_b.to(DEVICE)\n",
    "            y_r = y_r.to(DEVICE)\n",
    "            y_u = y_u.to(DEVICE)\n",
    "            y_truth = pack_y(y_main, y_type, y_t, y_b, y_r, y_u)\n",
    "            y = model(x)\n",
    "\n",
    "            info = data_eval(y, y_truth)\n",
    "            if info_sum is None:\n",
    "                info_sum = info\n",
    "            else:\n",
    "                info_sum = { key: info_sum[key] + info[key] for key in info.keys() }\n",
    "                \n",
    "            # print('getting lbls_g ..')\n",
    "            lbls_g = y_to_lbls(y_truth, preproc, W_b, w, conf_threshold=0.5)\n",
    "            # print('getting lbls_p ..')\n",
    "            lbls_p = y_to_lbls(y, preproc, W_b, w)\n",
    "            \n",
    "            for P, G in zip(lbls_p, lbls_g):\n",
    "                # print('ap30')\n",
    "                AP30 = compute_AP(P, G, iou_threshold=0.3)\n",
    "                # print('ap50')\n",
    "                AP50 = compute_AP(P, G, iou_threshold=0.5)\n",
    "                # print('ap70')\n",
    "                AP70 = compute_AP(P, G, iou_threshold=0.7)\n",
    "                AP30s.append(AP30)\n",
    "                AP50s.append(AP50)\n",
    "                AP70s.append(AP70)\n",
    "                weights.append(len(P))\n",
    "                \n",
    "                first_flag -= 1\n",
    "                if first_flag == 0:\n",
    "                    pr_curve(P, G, output_name=pr_curve_output_path)\n",
    "                    first_flag = 0\n",
    "                \n",
    "            item_count += info['items']\n",
    "    \n",
    "    weighted_mAP30 = np.average(AP30s, weights=weights)\n",
    "    weighted_mAP50 = np.average(AP50s, weights=weights)\n",
    "    weighted_mAP70 = np.average(AP70s, weights=weights)\n",
    "    \n",
    "    res = {}\n",
    "    if info_sum['c_tp'] + info_sum['c_fn'] > 0:\n",
    "        res.update({\n",
    "            **{ key: info_sum[key] / (info_sum['c_tp'] + info_sum['c_fn']) for key in info.keys() if key[:4] == 'ccc_' },\n",
    "            'c_r': info_sum['c_tp'] / (info_sum['c_tp'] + info_sum['c_fn']),\n",
    "        })\n",
    "    else:\n",
    "        res.update({\n",
    "            **{ key: 0 for key in info.keys() if key[:4] == 'ccc_' },\n",
    "            'c_r': 0,\n",
    "        })\n",
    "    if info_sum['c_tp'] + info_sum['c_fp'] > 0:\n",
    "        res.update({\n",
    "            'c_p': info_sum['c_tp'] / (info_sum['c_tp'] + info_sum['c_fp']),\n",
    "        })\n",
    "    else:\n",
    "        res.update({\n",
    "            'c_p': 0,\n",
    "        })\n",
    "    return {\n",
    "        **res,\n",
    "        'c_dist': info_sum['c_dist'] / item_count,\n",
    "        'c_acc': (info_sum['c_tp'] + info_sum['c_tn']) / item_count,\n",
    "        'ap30': weighted_mAP30,\n",
    "        'ap50': weighted_mAP50,\n",
    "        'ap70': weighted_mAP70,\n",
    "        'item_sum': item_count,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ebd02-d4dd-4007-afea-1224b04fcf33",
   "metadata": {},
   "source": [
    "## [B3] 可视化评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40942b40-71f2-43fb-8e23-26fd56de2653",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [B3a] 进行分布指标评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5532b4e2-a4ee-4bd4-bb04-a3c23200de7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_epoch_theta_y(model, test_loader, debug=False):\n",
    "\n",
    "    q_truth = []\n",
    "    q_diff = []\n",
    "    l_truth = []\n",
    "    l_diff = []\n",
    "    r_truth = []\n",
    "    r_diff = []\n",
    "    c_truth = []\n",
    "    c_diff = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y_main, y_type, y_t, y_b, y_r, y_u, _ in tqdm(test_loader, ascii=True) if debug else test_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = model(x)\n",
    "            y = { key: y[key].detach().cpu().numpy() for key in y.keys() }\n",
    "            y_truth = pack_y(y_main.numpy(), y_type.numpy(), y_t.numpy(), y_b.numpy(), y_r.numpy(), y_u.numpy())\n",
    "            ct = (y_truth['c'] >= 0.5)\n",
    "            \n",
    "            c_truth.extend(y_truth['c'].flatten().tolist())\n",
    "            c_diff.extend((y_truth['c'] - y['c']).flatten().tolist())\n",
    "            q_truth.extend(y_truth['q'][ct].tolist())\n",
    "            q_diff.extend((y_truth['q'][ct] - y['q'][ct]).tolist())\n",
    "            l_truth.extend(y_truth['l'][ct].tolist())\n",
    "            l_diff.extend((y_truth['l'][ct] - y['l'][ct]).tolist())\n",
    "            r_truth.extend(y_truth['r'][ct].tolist())\n",
    "            r_diff.extend((y_truth['r'][ct] - y['r'][ct]).tolist())\n",
    "            \n",
    "    return [(q_truth, q_diff), (l_truth, l_diff), (r_truth, r_diff), (c_truth, c_diff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd131552-efea-4e60-882e-283ba4fc8030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_hist_info(eval_list, output_name=None):\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=(7, 9), nrows=len(eval_list))\n",
    "    \n",
    "    infos = [\n",
    "        {\n",
    "            'title': 'q',\n",
    "            'unit': 'specified',\n",
    "        },\n",
    "        {\n",
    "            'title': 'l',\n",
    "            'unit': 'pixel',\n",
    "        },\n",
    "        {\n",
    "            'title': 'r',\n",
    "            'unit': 'pixel',\n",
    "        },\n",
    "        {\n",
    "            'title': 'c',\n",
    "            'unit': 'conf',\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    for (truth, diff), ax, info in zip(eval_list, axes, infos):\n",
    "        \n",
    "        vdiff = truth - np.average(np.array(truth))\n",
    "        bins = np.histogram_bin_edges(np.concatenate((vdiff, diff)), bins=100)\n",
    "        ax.hist(vdiff, bins=bins, density=False, label=r\"truths $y - \\overline{y}$ \", color='#5599CC')\n",
    "        ax.hist(diff, bins=bins, density=False, label=r\"prediction error $ y - h(x) $\", alpha=0.6, color='#BB2222')\n",
    "        ax.set_xlabel('Value (' + info['unit'] + ')')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.set_title(info['title'])\n",
    "        ax.legend()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    if output_name is not None:\n",
    "        fig.savefig(output_name)\n",
    "        plt.close(fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308b8e2-6df0-4e55-a2e7-505a12ab732b",
   "metadata": {},
   "source": [
    "## [B4] 进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590bde22-657d-4a16-8f6a-8a30302ddcfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 实例化定义的模型\n",
    "model = NoteCNN().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0d081-db66-4856-94fa-13f5478b3497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义优化器为改动更新所有层级\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# MSELoss\n",
    "loss_q = nn.MSELoss()\n",
    "loss_l = nn.MSELoss()\n",
    "loss_r = nn.MSELoss()\n",
    "loss_c_obj = nn.MSELoss()\n",
    "loss_c_noobj = nn.MSELoss()\n",
    "# 采用交叉熵损失函数\n",
    "loss_type = nn.CrossEntropyLoss()\n",
    "loss_dot_t = nn.CrossEntropyLoss()\n",
    "loss_dot_b = nn.CrossEntropyLoss()\n",
    "loss_dot_r = nn.CrossEntropyLoss()\n",
    "loss_uline = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f5d21-5c8a-44b2-b036-be31a14d5e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 测试评估函数的效果\n",
    "# eval_epoch(model, test_loader, preproc, 16, 1280, debug=True, pr_curve_output_path='0_pr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27abfec2-6450-4222-a595-36f4151dbd67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eval_list = eval_epoch_theta_y(model, test_loader, debug=True)\n",
    "# plot_hist_info(eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7565ee4a-b105-4b6b-9e7d-b556e6e149d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "# x, _, _ = next(iter(train_loader))\n",
    "# y = model(x.to(DEVICE))\n",
    "# output = make_dot(y.mean(), params=dict(model.named_parameters()), show_attrs=True, show_saved=True)\n",
    "# output.format = \"png\"\n",
    "# output.directory = \".\"\n",
    "# output.render(\"torchviz\", view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94afc7c-00e7-4ce0-b126-2e194472201e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "CKPT_FOLDER = '.\\\\ckpts_xs_notes'\n",
    "HIST_FOLDER = '..\\\\hists_xs_notes'\n",
    "\n",
    "if not os.path.exists(CKPT_FOLDER):\n",
    "    os.makedirs(CKPT_FOLDER)\n",
    "if not os.path.exists(HIST_FOLDER):\n",
    "    os.makedirs(HIST_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf46cca6-1976-4ffc-a222-bd82b3ecb7d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "step = 1\n",
    "subtask_switch_step = 2\n",
    "N_out = 10\n",
    "uniform_randweight = np.ones(shape=(N_out,), dtype=np.float32) / N_out\n",
    "def get_new_randweight():\n",
    "    res = np.random.rand(N_out)\n",
    "    summ = np.sum(res)\n",
    "    if summ > 0:\n",
    "        return res / summ\n",
    "    else:\n",
    "        return uniform_randweight\n",
    "subtask_randweight = get_new_randweight()\n",
    "def subtask_decay(step):\n",
    "    return 0.93 ** step\n",
    "    \n",
    "for epoch_i in range(1, EPOCHS+1):\n",
    "    batch_i = 1\n",
    "    print('epoch %d/%d' % (epoch_i, EPOCHS))\n",
    "    for x, y_main, y_type, y_t, y_b, y_r, y_u, _ in tqdm(train_loader, ascii=True):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        x = x.to(DEVICE)\n",
    "        y_main = y_main.to(DEVICE)\n",
    "        y_type = y_type.to(DEVICE)\n",
    "        y_t = y_t.to(DEVICE)\n",
    "        y_b = y_b.to(DEVICE)\n",
    "        y_r = y_r.to(DEVICE)\n",
    "        y_u = y_u.to(DEVICE)\n",
    "        y_truth = pack_y(y_main, y_type, y_t, y_b, y_r, y_u)\n",
    "        ct = (y_truth['c'] >= 0.5)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y = model(x)\n",
    "        \n",
    "        l_obj = loss_c_obj(y['c'][ct], y_truth['c'][ct]) * 20\n",
    "        l_noobj = loss_c_noobj(y['c'][~ct], y_truth['c'][~ct]) * 10\n",
    "        l_q = loss_q(y['q'][ct], y_truth['q'][ct]) * 20\n",
    "        l_l = loss_l(y['l'][ct], y_truth['l'][ct]) / 2\n",
    "        l_r = loss_r(y['r'][ct], y_truth['r'][ct]) / 2\n",
    "        l_type = loss_type(y['type'].view(-1, y['type'].size(-1)), y_truth['type'].view(-1))\n",
    "        l_dot_t = loss_dot_t(y['dot_t'].view(-1, y['dot_t'].size(-1)), y_truth['dot_t'].view(-1))\n",
    "        l_dot_b = loss_dot_b(y['dot_b'].view(-1, y['dot_b'].size(-1)), y_truth['dot_b'].view(-1))\n",
    "        l_dot_r = loss_dot_r(y['dot_r'].view(-1, y['dot_r'].size(-1)), y_truth['dot_r'].view(-1))\n",
    "        l_uline = loss_uline(y['uline'].view(-1, y['uline'].size(-1)), y_truth['uline'].view(-1))\n",
    "        \n",
    "        decay = subtask_decay(step)\n",
    "        weights = subtask_randweight * (decay) + uniform_randweight * (1 - decay)\n",
    "        loss = 0\n",
    "        for l, w in zip([l_q, l_l, l_r, l_obj, l_noobj, l_type, l_dot_t, l_dot_b, l_dot_r, l_uline], weights.tolist()):\n",
    "            loss += l * w\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_i % 512 == 0:\n",
    "            info = {\n",
    "                'train_epoch_i': epoch_i,\n",
    "                'train_batch_i': batch_i,\n",
    "                'loss': loss.item(),\n",
    "                'loss_q': l_q.item(),\n",
    "                'loss_l': l_l.item(),\n",
    "                'loss_r': l_r.item(),\n",
    "                'loss_obj': l_obj.item(),\n",
    "                'loss_noobj': l_noobj.item(),\n",
    "                'loss_dot_t': l_dot_t.item(),\n",
    "                'loss_dot_b': l_dot_b.item(),\n",
    "                'loss_dot_r': l_dot_r.item(),\n",
    "                'loss_uline': l_uline.item(),\n",
    "                **eval_epoch(model, test_loader, preproc, 16, 1280),\n",
    "            }\n",
    "            if WANDB:\n",
    "                wandb.log(info)\n",
    "            step += 1\n",
    "            \n",
    "            NOW_SAVING_TO = os.path.join(CKPT_FOLDER, 'xsn(norm)_model_step=%04d.ckpt' % step)\n",
    "            torch.save(model, NOW_SAVING_TO)\n",
    "            # print(\"已保存模型至：\", NOW_SAVING_TO)\n",
    "            \n",
    "            if step % 3 == 0:\n",
    "                eval_list = eval_epoch_theta_y(model, test_loader, debug=False)\n",
    "                plot_hist_info(eval_list, output_name=os.path.join(HIST_FOLDER, 'xsn(norm)_hist_step=%04d.png' % step))\n",
    "    \n",
    "        if batch_i % 50 == 0:\n",
    "            subtask_randweight = get_new_randweight()\n",
    "\n",
    "        batch_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a60c5e-3801-4a38-a9b4-437a1a0d87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW_SAVING_TO = os.path.join(CKPT_FOLDER, 'model_final.ckpt')\n",
    "# torch.save(model, NOW_SAVING_TO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef782e-249d-4c8c-882f-b3ec5b2de4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOW_LOADING_FROM = os.path.join(CKPT_FOLDER, 'model_final_best.ckpt')\n",
    "# model = torch.load(NOW_LOADING_FROM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f500e33-2283-4663-9bce-0298162c196d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 测试评估函数的效果\n",
    "# eval_epoch(model, test_loader, preproc, 16, 1280, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
